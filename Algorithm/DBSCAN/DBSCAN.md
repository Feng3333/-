# DBSCAN--基于密度的聚类算法

## 1. DBSCAN简介
DBSCAN（Density-Based Spatial Clustering of Applications with Noise，具有噪声的基于密度的聚类方法）是一种典型的基于密度的空间聚类算法，DBSCAN既可以适用于凸样本集，也可以适用于非凸样本集。该算法将具有足够密度的区域划分为簇，并在具有噪声的空间数据库中发现任意形状的簇，它将簇定义为密度相连的点的最大集合。  

该算法利用基于密度的聚类的概念，即要求聚类空间中的一定区域内所包含对象（点或其他空间对象）的数目不小于某一给定阈值。DBSCAN算法的显著优点是聚类速度快且能够有效处理噪声点和发现任意形状的空间聚类。但是当空间聚类的密度不均匀、聚类间距差相差很大时，聚类质量较差。

## 2. DBSCAN的优缺点 

### 优点：
1. 可以对任意形状的稠密数据集进行聚类，相对的，K-Means之类的聚类算法一般只适用于凸数据集。 
2. 可以在聚类的同时发现异常点，对数据集中的异常点不敏感。 
3. 聚类结果没有偏倚，相对的，K-Means之类的聚类算法初始值对聚类结果有很大影响。

### 缺点：
1. 如果样本集的密度不均匀、聚类间距差相差很大时，聚类质量较差，这时用DBSCAN聚类一般不适合。 
2. 如果样本集较大时，聚类收敛时间较长，此时可以对搜索最近邻时建立的KD树或者球树进行规模限制来改进。 
3. 调参相对于传统的K-Means之类的聚类算法稍复杂，主要需要对距离阈值ϵ，邻域样本数阈值MinPts联合调参，不同的参数组合对最后的聚类效果有较大影响

## 3. DBSCAN详细描述和参数含义

DBSCAN是基于一组邻域来描述样本集的紧密程度的，参数 $(ϵ, MinPts)$ 用来描述邻域的样本分布紧密程度。其中，$ϵ$ 描述了某一样本的邻域距离阈值，$MinPts$ 描述了某一样本的距离为 $ϵ$ 的邻域中样本个数的阈值。  
假设样本集是 $D=(x1,x2,...,xm)$ ，则DBSCAN具体的密度描述如下：  　　
1. $ϵ$-邻域：对于$xj∈D$，其 $ϵ$-邻域 包含样本集 $D$ 中与 $xj$ 的距离不大于ϵ的子样本集，即 $Nϵ(xj)={xi∈D|distance(xi,xj)≤ϵ}$ , 这个子样本集的个数记为$ |Nϵ(xj)|$  　　
2. 核心对象：对于任一样本 $xj∈D$ ，如果其 ϵ-邻域 对应的 $Nϵ(xj)$ 至少包含 $MinPts$ 个样本，即如果 $|Nϵ(xj)|≥MinPts$ ，则 $xj$ 是核心对象。  
3. 密度直达：如果 $xi$ 位于 $xj$ 的 ϵ-邻域 中，且 $xj$ 是核心对象，则称 $xi$ 由 $xj$ 密度直达。注意反之不一定成立，即此时不能说 $xj$ 由 $xi$ 密度直达, 除非且 $xi$ 也是核心对象。  
4. 密度可达：对于 $xi$ 和 $xj$ ,如果存在样本样本序列 $p1,p2,...,pT$ ,满足 $p1=xi$ , $pT=xj$ , 且$pt+1$ 由 $pt$ 密度直达，则称 $xj$ 由 $xi$ 密度可达。也就是说，密度可达满足传递性。此时序列中的传递样本 $p1,p2,...,pT−1$ 均为核心对象，因为只有核心对象才能使其他样本密度直达。注意密度可达也不满足对称性，这个可以由密度直达的不对称性得出。  
5. 密度相连：对于 $xi$ 和 $xj$ ,如果存在核心对象样本 $xk$，使 $xi$ 和 $xj$ 均由 $xk$ 密度可达，则称 $xi$ 和 $xj$ 密度相连。注意密度相连关系是满足对称性的。

## 4. DBSCAN思想
DBSCAN的聚类定义很简单：由密度可达关系导出的最大密度相连的样本集合，即为我们最终聚类的一个类别，或者说一个簇。  
这个DBSCAN的簇里面可以有一个或者多个核心对象。如果只有一个核心对象，则簇里其他的非核心对象样本都在这个核心对象的 $ϵ$-邻域 里；如果有多个核心对象，则簇里的任意一个核心对象的ϵ-邻域中一定有一个其他的核心对象，否则这两个核心对象无法密度可达。这些核心对象的 $ϵ$-邻域 里所有的样本的集合组成的一个DBSCAN聚类簇。  
那么怎么才能找到这样的簇样本集合呢？DBSCAN使用的方法很简单，它任意选择一个没有类别的核心对象作为种子，然后找到所有这个核心对象能够密度可达的样本集合，即为一个聚类簇。接着继续选择另一个没有类别的核心对象去寻找密度可达的样本集合，这样就得到另一个聚类簇。一直运行到所有核心对象都有类别为止。  
这基本上就是DBSCAN算法的主要内容了，但是还有三个问题没有考虑：  
1. 一些异常样本点或者说少量游离于簇外的样本点，这些点不在任何一个核心对象在周围，在DBSCAN中，我们一般将这些样本点标记为噪音点。  
2. 距离的度量问题，即如何计算某样本和核心对象样本的距离。在DBSCAN中，一般采用最近邻思想，采用某一种距离度量来衡量样本距离，比如欧式距离。这和KNN分类算法的最近邻思想完全相同。对应少量的样本，寻找最近邻可以直接去计算所有样本的距离，如果样本量较大，则一般采用KD树或者球树来快速的搜索最近邻。  
3. 第三种问题比较特殊，某些样本可能到两个核心对象的距离都小于 $ϵ$，但是这两个核心对象由于不是密度直达，又不属于同一个聚类簇，那么如果界定这个样本的类别呢？一般来说，此时DBSCAN采用先来后到，先进行聚类的类别簇会标记这个样本为它的类别。也就是说DBSCAN的算法不是完全稳定的算法

## 5. DBSCAN算法步骤

输入：样本集 $D=(x1,x2,...,xm)$ ，邻域参数 $(ϵ,MinPts)$ , 样本距离度量方式  
输出：簇划分 $C$

1. 初始化核心对象集合 $Ω=∅$ , 初始化聚类簇数 $k=0$ ，初始化未访问样本集合 $Γ = D$ , 簇划分 $C = ∅$
2. 对于 $j=1,2,...m$ ， 按下面的步骤找出所有的核心对象：
   - a 通过距离度量方式，找到样本 $xj$ 的 $ϵ-$邻域子样本集 $Nϵ(xj)$
   - b 如果子样本集样本个数满足 $|Nϵ(xj)|≥MinPts$ ， 将样本xj加入核心对象样本集合：$Ω=Ω∪{xj}$
3. 如果核心对象集合 $Ω=∅$ ，则算法结束，否则转入步骤4
4. 在核心对象集合 $Ω$ 中，随机选择一个核心对象 $o$ ，初始化当前簇核心对象队列 $Ωcur={o}$, 初始化类别序号 $k=k+1$ ，初始化当前簇样本集合 $Ck={o}$, 更新未访问样本集合 $Γ=Γ−{o}$
5. 如果当前簇核心对象队列 $Ωcur=∅$ ，则当前聚类簇 $Ck$ 生成完毕, 更新簇划分 $C={C1,C2,...,Ck}$ , 更新核心对象集合 $Ω=Ω−Ck$ ， 转入步骤3。否则更新核心对象集合 $Ω=Ω−Ck$。
6. 在当前簇核心对象队列 $Ωcur$ 中取出一个核心对象 $o′$ ,通过邻域距离阈值 $ϵ$ 找出所有的$ϵ$-邻域 子样本集 $Nϵ(o′)$ ，令 $Δ=Nϵ(o′)∩Γ$ , 更新当前簇样本集合 $Ck=Ck∪Δ$ , 更新未访问样本集合 $Γ=Γ−Δ$, 更新 $Ωcur=Ωcur∪(Δ∩Ω)−o′$ ，转入步骤5.
输出结果为： 簇划分 $C={C1,C2,...,Ck}$
